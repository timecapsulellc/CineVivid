# ðŸŒ CineVivid Hosting & Deployment Guide

**Complete hosting strategy for smooth AI video generation at scale**

---

## ðŸŽ¯ **TESTING ALL AI FUNCTIONS**

### **Quick Function Test**
```bash
# Run comprehensive AI tools testing
cd SkyReels-V2
python test_ai_functions.py

# Expected output:
# âœ… AUTHENTICATION      PASS
# âœ… HEALTH             PASS  
# âœ… PROMPT_ENHANCEMENT PASS
# âœ… TEXT_TO_VIDEO      PASS
# Overall: 4/4 tests passed (100.0%)
```

### **Manual UI Testing Checklist**
```bash
# 1. Start services
docker-compose up -d

# 2. Test each AI tool:
# Frontend: http://localhost:3000
# - Click "AI Video" â†’ Enter prompt â†’ Generate
# - Click "AI Drama" â†’ Create story â†’ Preview
# - Click "Generate Image" â†’ Text prompt â†’ Generate
# - Click "Talking Avatar" â†’ Text + voice â†’ Animate
# - Click "Lip Sync" â†’ Upload video + audio â†’ Sync
# - Click "Video Editor" â†’ Upload â†’ Edit â†’ Export
```

---

## ðŸ† **RECOMMENDED HOSTING PLATFORMS**

### **ðŸ¥‡ BEST: Google Cloud Platform (GCP)**

#### **Why GCP for CineVivid:**
- **ðŸ’° Cost-Effective**: Preemptible GPU instances (70% savings)
- **ðŸš€ GPU Performance**: NVIDIA T4, V100, A100 available
- **ðŸ“ˆ Auto-Scaling**: Kubernetes for demand management
- **ðŸ›¡ï¸ Enterprise Security**: VPC, IAM, encryption
- **ðŸ’¾ Fast Storage**: SSD persistent disks for model caching

#### **GCP Production Configuration**
```yaml
# gcp-production.yaml
Compute Engine:
  instance_type: n1-standard-8 (8 vCPU, 30GB RAM)
  gpu: nvidia-tesla-t4 (1x GPU, 16GB VRAM)
  disk: 200GB SSD persistent disk
  region: us-central1-a
  preemptible: true # 70% cost savings

Load Balancer:
  type: Global HTTPS Load Balancer
  ssl: Google-managed certificates
  cdn: Cloud CDN enabled

Database:
  type: Cloud SQL PostgreSQL
  tier: db-standard-2 (2 vCPU, 7.5GB)
  storage: 100GB SSD
  backup: automated daily

Storage:
  type: Cloud Storage
  class: Standard
  location: US multi-region
```

#### **Monthly Cost (GCP)**
```
VM (n1-standard-8 preemptible): $140/month
GPU (T4 preemptible): $80/month
Storage (200GB SSD): $34/month  
Database (Cloud SQL): $65/month
Load Balancer: $18/month
Network: $30/month
Total: ~$367/month
```

#### **GCP Deployment Steps**
```bash
# 1. Setup GCP project
gcloud config set project cinevivid-production
gcloud services enable compute.googleapis.com
gcloud services enable container.googleapis.com

# 2. Create VM with GPU
gcloud compute instances create cinevivid-vm \
  --zone=us-central1-a \
  --machine-type=n1-standard-8 \
  --accelerator=count=1,type=nvidia-tesla-t4 \
  --preemptible \
  --image-family=ubuntu-2004-lts \
  --image-project=ubuntu-os-cloud \
  --boot-disk-size=200GB \
  --boot-disk-type=pd-ssd \
  --tags=cinevivid-server

# 3. Install dependencies
gcloud compute ssh cinevivid-vm --zone=us-central1-a
sudo apt update && sudo apt install -y nvidia-driver-470 docker.io
sudo systemctl enable docker && sudo systemctl start docker

# 4. Deploy application
git clone https://github.com/timecapsulellc/CineVivid
cd CineVivid/SkyReels-V2
python setup_production.py --domain your-domain.com

# 5. Setup load balancer
gcloud compute forwarding-rules create cinevivid-lb \
  --global \
  --target-http-proxy=cinevivid-proxy \
  --ports=80,443
```

---

### **ðŸ¥ˆ ALTERNATIVE: AWS EC2 + ECS**

#### **AWS Configuration**
```yaml
# aws-production.yaml
EC2 Instance:
  type: g4dn.2xlarge (8 vCPU, 32GB RAM)
  gpu: NVIDIA T4 (1x, 16GB VRAM)
  storage: 200GB gp3 SSD
  spot_instance: true # 50-70% savings

ECS Cluster:
  launch_type: EC2
  service: cinevivid-service
  desired_count: 1
  auto_scaling: enabled

Database:
  type: RDS PostgreSQL
  instance: db.t3.medium
  storage: 100GB gp2
  multi_az: false

Load Balancer:
  type: Application Load Balancer
  ssl: ACM certificate
  health_check: /health
```

#### **Monthly Cost (AWS)**
```
EC2 (g4dn.2xlarge spot): $280/month
RDS PostgreSQL: $50/month
EBS Storage: $20/month
ALB: $25/month
Data Transfer: $40/month
Total: ~$415/month
```

#### **AWS Deployment**
```bash
# 1. Create ECS cluster
aws ecs create-cluster --cluster-name cinevivid-cluster

# 2. Deploy with CDK/Terraform
cd aws-deployment
terraform init
terraform plan -var="domain=your-domain.com"
terraform apply

# 3. Monitor deployment
aws ecs describe-services --cluster cinevivid-cluster --services cinevivid-service
```

---

### **ðŸ¥‰ BUDGET: Vast.ai + Railway Hybrid**

#### **Ultra Cost-Effective Setup**
```yaml
Frontend: Vercel (Free tier)
API: Railway ($5-20/month)  
GPU: Vast.ai on-demand ($0.15-0.50/hour)
Database: PlanetScale (Free tier)
CDN: Cloudflare (Free tier)
Storage: Cloudflare R2 ($0.015/GB)
```

#### **Monthly Cost (Budget)**
```
Frontend (Vercel): $0
API (Railway): $20/month
GPU (Vast.ai): $50-150/month (usage-based)
Database (PlanetScale): $0
Storage (Cloudflare R2): $5/month
Total: ~$75-175/month
```

#### **Budget Setup Process**
```bash
# 1. Deploy frontend to Vercel
cd src/frontend
npm run build
npx vercel --prod

# 2. Deploy API to Railway
# Connect GitHub repo to Railway
# Set environment variables
# Auto-deploy from main branch

# 3. Setup GPU processing
# Create Vast.ai account
# Setup API endpoint for GPU calls
# Configure hybrid processing
```

---

## ðŸš€ **PRODUCTION HOSTING CONFIGURATIONS**

### **ðŸ”§ Optimal Server Specs by Usage**

#### **Small Scale (100-1000 users/month)**
```yaml
CPU: 4 cores, 16GB RAM
GPU: NVIDIA T4 (16GB VRAM) 
Storage: 100GB SSD
Network: 10Gbps
Cost: ~$200-300/month
Providers: Railway, Render, DigitalOcean
```

#### **Medium Scale (1K-10K users/month)**
```yaml
CPU: 8 cores, 32GB RAM
GPU: NVIDIA V100 (32GB VRAM)
Storage: 500GB SSD  
Network: 25Gbps
Cost: ~$500-800/month
Providers: GCP, AWS, Azure
```

#### **Large Scale (10K+ users/month)**
```yaml
CPU: 16+ cores, 64GB+ RAM
GPU: Multiple A100s (40GB+ VRAM each)
Storage: 1TB+ NVMe SSD
Network: 100Gbps+
Cost: ~$2000+/month
Providers: GCP, AWS with auto-scaling
```

### **ðŸŽ¯ Performance Requirements**

#### **GPU Requirements by Model**
```yaml
SkyReels-V2-1.3B-540P:
  min_vram: 8GB
  recommended_vram: 16GB
  generation_time: 2-3 minutes

SkyReels-V2-14B-540P:  
  min_vram: 24GB
  recommended_vram: 32GB
  generation_time: 3-5 minutes

SkyReels-V2-14B-720P:
  min_vram: 48GB  
  recommended_vram: 80GB
  generation_time: 5-8 minutes
```

#### **Storage Requirements**
```yaml
Application Code: 2GB
SkyReels-V2 Models: 50-100GB
Video Storage: 50GB+ (grows with usage)
Database: 10GB+ (grows with users)
Logs: 5GB (with rotation)
Total Minimum: 120GB
Recommended: 200GB+ SSD
```

### **ðŸ’° Cost Optimization Strategies**

#### **1. Spot/Preemptible Instances**
```bash
# Save 50-70% on compute costs
# Auto-restart handling in application
# Use for non-critical processing
```

#### **2. Model Optimization**
```python
# Use quantization for memory efficiency
USE_QUANTIZATION=true  # Reduces VRAM by 50%
MODEL_OFFLOAD_CPU=true # Offload when not in use

# Start with smaller models
DEFAULT_MODEL=Skywork/SkyReels-V2-1.3B-540P
```

#### **3. Hybrid Processing**
```yaml
# Frontend: CDN (Vercel/Cloudflare)
# API: Cheap VPS (Railway/Render) 
# GPU: On-demand (Vast.ai/RunPod)
# Database: Managed service (PlanetScale/Supabase)
```

---

## âš¡ **DEPLOYMENT AUTOMATION**

### **One-Click Deployment Scripts**

#### **GCP Deployment**
```bash
#!/bin/bash
# deploy_gcp.sh

# Set project and region
gcloud config set project $GCP_PROJECT_ID
gcloud config set compute/zone us-central1-a

# Create instance
gcloud compute instances create cinevivid-production \
  --machine-type=n1-standard-8 \
  --accelerator=count=1,type=nvidia-tesla-t4 \
  --preemptible \
  --image-family=ubuntu-2004-lts \
  --image-project=ubuntu-os-cloud \
  --boot-disk-size=200GB \
  --boot-disk-type=pd-ssd

# Setup and deploy
gcloud compute ssh cinevivid-production --command="
  curl -fsSL https://get.docker.com | sudo sh
  git clone https://github.com/timecapsulellc/CineVivid
  cd CineVivid/SkyReels-V2
  python setup_production.py --domain $DOMAIN
"

echo "ðŸš€ GCP deployment completed!"
echo "Access: https://$DOMAIN"
```

#### **AWS Deployment**
```bash
#!/bin/bash
# deploy_aws.sh

# Create EC2 instance
aws ec2 run-instances \
  --image-id ami-0c02fb55956c7d316 \
  --instance-type g4dn.2xlarge \
  --key-name your-key-pair \
  --security-groups cinevivid-sg \
  --user-data file://user-data.sh

echo "ðŸš€ AWS deployment initiated!"
```

### **Docker Swarm for Multi-Node**
```yaml
# docker-swarm.yml
version: '3.8'
services:
  backend:
    image: cinevivid/backend:latest
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.role == worker
          - node.labels.gpu == true
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## ðŸ“Š **MONITORING & SCALING**

### **Performance Monitoring**
```yaml
# monitoring-config.yml
metrics:
  - gpu_memory_usage
  - video_generation_time  
  - api_response_time
  - user_active_sessions
  - credit_consumption_rate

alerts:
  - gpu_memory > 90%
  - generation_time > 10min
  - error_rate > 5%
  - disk_space < 10GB
```

### **Auto-Scaling Configuration**
```yaml
# scaling-policy.yml
scale_up_triggers:
  - cpu_utilization > 70%
  - gpu_utilization > 80%
  - queue_length > 10

scale_down_triggers:
  - cpu_utilization < 30%
  - gpu_utilization < 20%
  - queue_length < 2

min_instances: 1
max_instances: 5
```

---

## ðŸ›¡ï¸ **SECURITY CONFIGURATIONS**

### **Production Security Setup**
```bash
# security-setup.sh
# SSL/TLS
certbot --nginx -d your-domain.com

# Firewall
ufw allow 80,443/tcp
ufw allow 22/tcp
ufw enable

# Environment
export SECRET_KEY=$(openssl rand -hex 32)
export DATABASE_URL="postgresql://secure_user:$(openssl rand -base64 32)@localhost/cinevivid"

# Rate limiting
redis-cli CONFIG SET save "900 1"
```

### **Environment Variables (Production)**
```bash
# Critical security settings
SECRET_KEY=64_character_random_string
JWT_EXPIRE_MINUTES=30
RATE_LIMIT_PER_MINUTE=60
MAX_FILE_SIZE_MB=100
ALLOWED_HOSTS=your-domain.com,www.your-domain.com

# API keys (encrypted)
HUGGINGFACE_TOKEN=hf_encrypted_token
ELEVENLABS_API_KEY=sk_encrypted_key
STRIPE_SECRET_KEY=sk_live_encrypted
```

---

## ðŸ’¡ **EXPERT RECOMMENDATIONS**

### **ðŸŽ¯ Best Platform for Each Use Case**

#### **Startup/MVP (< 1K users)**
```
Platform: Railway + Vast.ai
Frontend: Vercel (free)
Cost: $75-150/month
Setup Time: 2 hours
Best for: Testing market fit
```

#### **Growing Business (1K-10K users)**
```
Platform: GCP with preemptible instances  
Cost: $350-500/month
Setup Time: 1 day
Best for: Scaling with predictable costs
```

#### **Enterprise (10K+ users)**
```
Platform: AWS/GCP with multi-region
Cost: $2000+/month
Setup Time: 1 week
Best for: Global scale with SLAs
```

### **ðŸš€ Quick Start Deployment**

#### **Option 1: Railway (Easiest)**
```bash
# 1-click deployment to Railway
# Connect GitHub repository
# Set environment variables:
HUGGINGFACE_TOKEN=your_token
ELEVENLABS_API_KEY=your_key
DATABASE_URL=postgresql://...

# Railway auto-deploys on git push
git push origin main
```

#### **Option 2: GCP (Best Performance)**
```bash
# Production deployment
cd SkyReels-V2
python setup_production.py --domain your-domain.com --provider gcp

# Automated setup includes:
# - VM creation with GPU
# - Docker installation  
# - SSL certificate
# - Database setup
# - Monitoring
```

#### **Option 3: Self-Hosted (Full Control)**
```bash
# On your own server
sudo apt update && sudo apt install docker.io
git clone https://github.com/timecapsulellc/CineVivid
cd CineVivid/SkyReels-V2
cp .env.example .env
# Edit .env with your keys
docker-compose -f docker-compose.prod.yml up -d
```

---

## ðŸŽ® **LOAD TESTING & PERFORMANCE**

### **Load Testing Script**
```python
#!/usr/bin/env python3
# load_test.py
import asyncio
import aiohttp
import time
import statistics

async def test_concurrent_generations():
    """Test concurrent video generations"""
    
    async with aiohttp.ClientSession() as session:
        # Login and get token
        async with session.post("http://localhost:8001/auth/login", json={
            "username": "demo", 
            "password": "demo123"
        }) as response:
            token = (await response.json())["access_token"]
            headers = {"Authorization": f"Bearer {token}"}
        
        # Create multiple concurrent requests
        tasks = []
        for i in range(5):  # Test 5 concurrent generations
            task = session.post(
                "http://localhost:8001/generate/text-to-video",
                json={
                    "prompt": f"Test video {i}: A beautiful landscape",
                    "num_frames": 25
                },
                headers=headers
            )
            tasks.append(task)
        
        # Execute all requests
        start_time = time.time()
        responses = await asyncio.gather(*tasks)
        duration = time.time() - start_time
        
        print(f"ðŸš€ Load Test Results:")
        print(f"   Concurrent requests: {len(tasks)}")
        print(f"   Total time: {duration:.2f}s")
        print(f"   Average per request: {duration/len(tasks):.2f}s")
        
        # Check all succeeded
        success_count = sum(1 for r in responses if r.status == 200)
        print(f"   Success rate: {success_count}/{len(tasks)} ({success_count/len(tasks)*100:.1f}%)")

# Run: python load_test.py
if __name__ == "__main__":
    asyncio.run(test_concurrent_generations())
```

### **Performance Benchmarks**

#### **Expected Performance (Production)**
```yaml
API Response Time:
  auth: < 100ms
  health: < 50ms
  video_generation_start: < 500ms
  
Video Generation Time:
  1.3B model (540P): 2-3 minutes
  14B model (540P): 3-5 minutes  
  14B model (720P): 5-8 minutes

Memory Usage:
  1.3B model: ~8GB VRAM
  14B model: ~24GB VRAM
  System RAM: ~8GB

Concurrent Users:
  Small setup: 10-50 concurrent
  Medium setup: 100-500 concurrent
  Large setup: 1000+ concurrent
```

---

## ðŸ”§ **TROUBLESHOOTING COMMON ISSUES**

### **GPU/Model Issues**
```bash
# Check GPU status
nvidia-smi

# Check model downloads
python -c "from src.utils.model_manager import get_model_manager; print(get_model_manager().get_cache_stats())"

# Re-download models
python -c "
from src.utils.model_manager import get_model_manager
manager = get_model_manager()
manager.download_model_sync('Skywork/SkyReels-V2-T2V-14B-540P')
"
```

### **Performance Issues**
```bash
# Monitor resource usage
docker stats

# Check logs for bottlenecks
docker-compose logs backend | grep "ERROR\|WARNING"

# Database performance
curl -H "Authorization: Bearer $ADMIN_TOKEN" http://localhost:8001/admin/stats
```

### **Scaling Issues**
```bash
# Scale workers
docker-compose up -d --scale celery_worker=3

# Check queue status
redis-cli LLEN video_generation_queue

# Monitor memory
free -h && df -h
```

---

## ðŸŽ¯ **EXPERT HOSTING DECISION MATRIX**

| Factor | Railway | GCP | AWS | Self-Hosted |
|--------|---------|-----|-----|-------------|
| **Setup Time** | 1 hour | 4 hours | 6 hours | 2 hours |
| **Monthly Cost** | $75-175 | $350-500 | $400-600 | $50-200 |
| **GPU Performance** | External | Excellent | Excellent | Variable |
| **Scaling** | Limited | Excellent | Excellent | Manual |
| **Maintenance** | Minimal | Low | Medium | High |
| **Control** | Limited | High | High | Full |

### **ðŸ† Expert Recommendation by Stage**

#### **ðŸš€ MVP/Testing: Railway + Vast.ai**
- **Pros**: Quick setup, low commitment, pay-per-use GPU
- **Cons**: Limited scaling, external GPU dependency
- **Best for**: Proof of concept, early user testing

#### **ðŸ“ˆ Production: Google Cloud Platform**
- **Pros**: Best price/performance, excellent GPU support, auto-scaling
- **Cons**: Learning curve, vendor lock-in
- **Best for**: Serious deployment with growth plans

#### **ðŸ¢ Enterprise: AWS Multi-Region**
- **Pros**: Global reach, enterprise features, compliance
- **Cons**: Higher costs, complexity
- **Best for**: Large scale with SLA requirements

---

## ðŸŽ¬ **READY FOR PRODUCTION!**

The CineVivid platform is **production-ready** with:

âœ… **Complete AI Pipeline**: All 6 tools implemented and tested
âœ… **Scalable Infrastructure**: Docker + Kubernetes ready
âœ… **Expert Monitoring**: Comprehensive health checks and performance metrics
âœ… **Cost Optimization**: Multiple hosting tiers from $75-2000/month
âœ… **Security**: Enterprise-grade authentication and data protection
âœ… **Documentation**: Complete setup and maintenance guides

**ðŸŽ¯ Choose hosting based on your scale and budget. Start with Railway for MVP, scale to GCP for production.**